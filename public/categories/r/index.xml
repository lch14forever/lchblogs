<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Chenhao&#39;s Personal Page</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Chenhao&#39;s Personal Page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© This site was created with R BlogDown and HuGo by Chenhao Li.</copyright>
    <lastBuildDate>Mon, 30 Aug 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>圆角barplot</title>
      <link>/post/2022-05-32-r-round-corner/</link>
      <pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2022-05-32-r-round-corner/</guid>
      <description>依赖 library(dplyr) ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union library(ggplot2)  数据 dat &amp;lt;- mutate(mtcars, index=1:n()) dat ## mpg cyl disp hp drat wt qsec vs am gear carb index ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 1 ## Mazda RX4 Wag 21.</description>
    </item>
    
    <item>
      <title>Emacs远程连接R</title>
      <link>/post/2018-11-25-emacs-remote-r/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-25-emacs-remote-r/</guid>
      <description> 本地的R脚本，远程执行 从事生信工作，已经形成了对R语言的重度依赖，Rstudio作为专注于R的IDE拥有强大的优势，但是我还是更习惯于Emacs的ESS的操作。其实之前就遇到过一个挺有意思的问题，如何用本地的Emacs去编辑并执行服务器上的R脚本。一个很显而易见的方法就是用Emacs的Tramp SSH连接到服务器，打开R脚本，这个时候ESS会自动使用远程服务器的R来运行。但是问题来了，在画图的时候这个远程的R进程并不能通过X11把图传回，所以会自动存储为Rplot.pdf于工作目录。Google了很久，找到了以解决方案：
打开本地shell/eshell (M-x shell/eshell) 在打开的shell中连接远程服务器（ssh -X user@remote.machine.ip 或 ssh -Y）并运行R 使用ESS remote（M-x ess-remote） 打开本地或远程（Tramp mode）的R脚本 使用C-c C-n（在CUA mode关闭情况下可使用C-Enter）或C-c C-c逐行或区域执行  在上述过程中，顺序其实不是很重要，唯一需要注意的是如果R脚本在服务器上，一定要先开启一个本地的shell，要不然Emacs会默认使用远程机器的shell。
为了简化此过程，我写了一个函数并把它定义给快捷键C-c C-r（写在init.el或.emacs文件中）：
(defun spawn-ess-remote (login) &amp;quot;connect to remote server and open ssh&amp;quot; (interactive &amp;quot;sUser login (uname@server.ip): &amp;quot;) (pop-to-buffer (get-buffer-create (generate-new-buffer-name &amp;quot;Remote-R&amp;quot;))) (shell (current-buffer)) (process-send-string nil (format&amp;quot;ssh -Y %s \n&amp;quot; login) ) (process-send-string nil &amp;quot;R\n&amp;quot;) (ess-remote nil &amp;quot;R&amp;quot;)) (global-set-key (kbd &amp;quot;C-c C-r&amp;quot;) &amp;#39;spawn-ess-remote)   </description>
    </item>
    
    <item>
      <title>一（三）文你读不懂PCA和PCoA</title>
      <link>/post/2018-04-39-r-pca_pcoa/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-04-39-r-pca_pcoa/</guid>
      <description>三文读懂PCA和PCoA？ 今天看到金唯智公众号的推文《三文读懂PCA和PCoA》（《一》,《二》,《三》)。作者以平民化的语言，剔除数学术语，介绍了二者的区别，是很好的尝试，但是文中提出的很多关键性总结，都存在着明显的漏洞。
特别指出在第二篇文章中：
“PCA基于物种丰度矩阵就意味着PCA分析的矩阵维度是就等于物种数目。换句话说，你要分析的样本如果要做PCA分析，那么一般来说有多少个物种就有多少个维度”。  既然说到丰度，那有一个很容易忽视的点，就是所有物种丰度相加为常数（1或100%），所以说数据的维数其实是物种数-1。而相对丰度其实并不在传统意义的欧式空间中（参见Aitchison的《The Statistical Analysis of Compositional Data》）。PCA涉及到的变换其实是会保持数据点之间欧式距离不变（考虑所有PC的话），那么PCA分析是否适用于丰度（成分）数据，是一个存在争议的课题（参见Aitchison的《Principal Component Analysis of Compositional Data》）。所以在成分数据（测序数据，特别是microbiome）数据的时候，我们常采用一些生态距离，然后做PCoA。
“同样的道理，PCoA基于样本间的距离矩阵就意味着PCoA分析的矩阵维度与样本数目相关。如果你要分析的样本做PCoA分析的话，那么一般来说有n个样本就至多有n-1个维度”。  这是一个n（样本数目）和p（维度）的问题，维度就是维度，p就是p，不能混淆。
“多数情况下，我们在做降维处理的时候，期望维数越低越好，这样我们就可以最大程度地保真原始数据”  天下没有免费的午餐，维数越低，保真度自然越低。而PCA、PCoA所做的是在低维空间中尽量多的保存数据之间的差异。
“如果样本数目比较多，而物种数目比较少，那肯定首选PCA；如果样本数目比较少，而物种数目比较多，那肯定首选PCoA”  这是一个很有意思的问题，其实PCoA和PCA的结果取决于PCoA的实现，但是直觉上想，既然PCA的变换会保存数据点间的欧氏距离，那么它和基于欧式距离的PCoA有什么区别呢？
下面做一个实验，我们用两组数据（样本数目&amp;gt;维度，纬度&amp;gt;样本数目）来看看R中常见的PCA和PCoA实现的结果有何不同。
iris：样本数目&amp;gt;维度 ## Low dimensional data (n&amp;gt;&amp;gt;p) data(iris) par(mfrow=c(2,2),cex=0.7, pch=19) ## PCA pca &amp;lt;- prcomp(iris[,-5]) plot(pca$x[,1:2], col=iris[,5], xlab=&amp;#39;PC1&amp;#39;,ylab=&amp;#39;PC2&amp;#39;, main=&amp;#39;PCA&amp;#39;) ## PCoA pcoa &amp;lt;- cmdscale(dist(iris[,-5], method = &amp;quot;euclidean&amp;quot;)) plot(pcoa, xlab=&amp;#39;MDS1&amp;#39;,ylab=&amp;#39;MDS2&amp;#39;, col=iris[,5], main=&amp;#39;PCoA&amp;#39;) ## pairwise distances plot(as.vector(dist(pca$x[,1:2])), as.vector(dist(pcoa)), xlab=&amp;#39;PCA&amp;#39;, ylab=&amp;#39;PCoA&amp;#39;, main=&amp;#39;Pairwise distances&amp;#39;, pch=19, col=rgb(0,0,0,0.3), cex=0.5) plot(as.vector(dist(pca$x[,1:2])) - as.</description>
    </item>
    
    <item>
      <title>成分之咒与ReBoot算法</title>
      <link>/post/2018-01-12-r-compositional/</link>
      <pubDate>Fri, 12 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-12-r-compositional/</guid>
      <description>写在前面 本文的大部分内容都来自我们之前的一篇综述文章Li et al, 2016。
 微生物组测序与成分数据 微生物组测序数据的获得其实有很多抽样过程（Sampling process）存在，比如说，粪便微生物组其实是对肠道微生物的一次抽样，测序的过程也是对所有DNA分子的一次抽样。最后，我们得到的OTU表中的OTU read count与测序深度相关，很显然测序深度是一个技术上的干扰因子（confounder），所以我们要对OTU表进行标准化（Normalization）。最简单的标准化方法，就是用read count除以样本内所有OTU的read count之和，获得每个OTU的相对丰度（relative abundance）。这种只有相对丰度的数据（相加总数为常数1或100）被称为成分数据（Compositional data）。 你可能注意到，作为成分数据一种的微生物组的数据中缺乏一个重要的信息–微生物总量（total abundance）。
 成分之咒（Curse of compositionality） （一些推导的废话可以跳过） 成分数据会对一些列统计分析产生影响，最典型的就是计算相关系数（correlation）。其中Pearson相关系数\(\rho_{X,Y}\)是由协方差矩阵算出来的，对于两个OTU的数量（由随机变量\(X\)，\(Y\)表示），相关系数可以按下面公式计算（详细解释见维基百科）：
\[COV(X, Y)=E[(X-E[X])(Y-E[Y])]\]
\[\rho_{X,Y}=\frac{COV(X,Y)}{\sqrt{COV(X,X)\times COV(Y,Y)}}\]
其中\(COV(X,X)\)其实就是\(X\)的方差。其中根据协方差的性质我们可以得出成分数据的协方差性质：
\[\sum_{i=1}^px_i=1 \Rightarrow \sum_{i=1,i\neq r}^pCOV(x_i, x_r)=-COV(x_r, x_r)\]
我们知道方差（\(COV(x_r, x_r)\)）一定为正值，所以成分数据的协方差（同理相关系数）天然趋向于负值！
 天然的负相关 上面的公式推导，其实简单的想一想，因为相加为1，所以一个OTU相对丰度增加，其他OTU必然减少，所以本来不相关的OTU数量在转化为成分数据后也会有负相关的趋势，也就是我们常见的微生物组领域所说的Compositional effect或Compositional bias。以下为简单的一个实验，Species 1和Speacies 2本来不相关，但是其相对丰度负相关：
## 加载r包 library(ggplot2) library(reshape2) library(cowplot) ## ggplot主题配置 figtheme &amp;lt;- theme_bw() + theme(text = element_text(size=10,face=&amp;#39;bold&amp;#39;),panel.border = element_rect(colour = &amp;quot;black&amp;quot;,size=2)) theme_set(figtheme) ## 随机产生独立的5个OTU绝对数量 means &amp;lt;- c(400,300,95,90,85) data &amp;lt;- sapply(means, function(x) rnorm(100, x, x*0.</description>
    </item>
    
    <item>
      <title>ggplot扩展学习笔记--逐行解析Y叔的&#34;geom_ord_ellipse.R&#34;</title>
      <link>/post/2018-01-09-r-ordellipsecode/</link>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-09-r-ordellipsecode/</guid>
      <description>介绍 看到Y叔为ggord做的添加置信椭圆的geom_ord_ellipse.R（用法见上一篇文章），决定学习一点ggplot图形的语言，对于初学者最好的方法就是照葫芦画瓢，而Y叔的代码自然是最好的模板。我对Y叔的代码进行了逐行的分析，希望以后有需要可以套用。
以下为geom_ord_ellipse.R代码。这个图层的代码其实很短，很简洁，但是如果想要透彻理解还是需要下些功夫的。
##&amp;#39; add confidence ellipse to ordinary plot produced by ggord ##&amp;#39; ##&amp;#39; ##&amp;#39; @title geom_ord_ellipse ##&amp;#39; @param mapping aes mapping ##&amp;#39; @param ellipse_pro confidence value for the ellipse ##&amp;#39; @param fill color to fill the ellipse, NA by default ##&amp;#39; @param ... additional parameters ##&amp;#39; @return ggplot layer ##&amp;#39; @importFrom ggplot2 aes_ ##&amp;#39; @importFrom ggplot2 layer ##&amp;#39; @importFrom utils modifyList ##&amp;#39; @export ##&amp;#39; @author Guangchuang Yu ##&amp;#39; @references \url{http://lchblogs.</description>
    </item>
    
    <item>
      <title>Generalized Lotka-Volterra model</title>
      <link>/post/2017-11-15-r-glv/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-11-15-r-glv/</guid>
      <description>The model \(\frac{dx_i}{dt}= ax_i+\sum_{j=1}^pb_{ij}x_ix_j\)
## library library(&amp;#39;deSolve&amp;#39;) ## GLV function lvm &amp;lt;- function(t, x, params){ with(as.list(params, c(x)), { dx &amp;lt;- alpha * x + x * (beta %*% x) list(dx) }) } ## numerical integration n.integrate &amp;lt;- function(time, init.x, model, params){ as.data.frame(ode(init.x, time, model, params)) } ## normalizations TSS &amp;lt;- function(x){ apply(x, 1, function(x)x/sum(x)) }  GLV with 3 species alpha &amp;lt;- c(0.1, 0.2, 0.3) beta &amp;lt;- t(matrix(c(-0.5, -0.3 , 0, 0.</description>
    </item>
    
    <item>
      <title>从curatedMetagenoimcData提取健康样本的微生物组</title>
      <link>/post/2017-11-07-r-curatedmetagenomicdata_retrievedata/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-11-07-r-curatedmetagenomicdata_retrievedata/</guid>
      <description>简介 有人问我，这个curatedMetagenomicData有什么作用？对于我们这些research parasite(出处请见NEJM社论)来说，这样庞大的数据集当然是用来挖信息或者是测试算法了：
作为validation cohort来验证已发现的结论。如我们的这篇文章都使用了2014年Oh et al发表于Nature的数据来佐证我们发现的Staphylococcus特异性突变。
 用来测试新方法，发现新的生物问题。如这篇文章中我们也用了Oh et al的数据来观测Malessezia在人体皮肤的分布。
 因为数据中有大量健康人的微生物组（不同研究中的control），我们也可以用它们补充我们的对照组（当然在机器学习中要注意数据不平衡问题）。
  当然最基础的操作，就是要从数据库中提取数据。
 演示 我们从curatedMetagenomicData中提取健康人的粪便及皮肤微生物组。
加载R package suppressMessages(library(curatedMetagenomicData)) suppressMessages(library(foreach))  下载并合并所有粪便、皮肤数据（下载数据缓存于~/.ExperimentHub中，第二次以后会直接读取缓存） ## download all stool samples stoolData &amp;lt;- curatedMetagenomicData(&amp;quot;*.metaphlan_bugs_list.stool&amp;quot;, dryrun=FALSE) ## Warning in strptime(x, fmt, tz = &amp;quot;GMT&amp;quot;): unknown timezone &amp;#39;zone/tz/2017c. ## 1.0/zoneinfo/Asia/Singapore&amp;#39; skinData &amp;lt;- curatedMetagenomicData(&amp;quot;*.metaphlan_bugs_list.skin&amp;quot;, dryrun=FALSE) ## merge stoolDataMerged &amp;lt;- mergeData(stoolData) skinDataMerged &amp;lt;- mergeData(skinData)  验证元数据与样本对应关系 table(rownames(pData(stoolDataMerged)) == colnames(exprs(stoolDataMerged))) ## ## TRUE ## 4810 table(rownames(pData(skinDataMerged)) == colnames(exprs(skinDataMerged))) ## ## TRUE ## 466  通过元数据来提取健康样本的数据 顺便过滤掉整行、整列为0的数据</description>
    </item>
    
    <item>
      <title>桑基图（Sankey diagram）II</title>
      <link>/post/2017-11-02-r-sankeyplot2/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-11-02-r-sankeyplot2/</guid>
      <description>使用plotly 预处理 taxtab &amp;lt;- read.table(&amp;#39;SRS014476-Supragingival_plaque_profile.txt&amp;#39;, sep=&amp;#39;\t&amp;#39;, stringsAsFactors=FALSE) second_last &amp;lt;- function(x) ifelse(length(x)&amp;gt;1, x[length(x)-1], NA) taxtab &amp;lt;- taxtab[-grep(&amp;#39;t__.*unclassified&amp;#39;, taxtab$V1), ] ## remove strain level tax_split &amp;lt;- strsplit(taxtab$V1, &amp;#39;\\|&amp;#39;) ## split into different taxonomy levels target &amp;lt;- sapply(tax_split, tail, n=1) ## target node mapping &amp;lt;- data.frame(id=0:(length(target)-1), row.names=target) target_id &amp;lt;- mapping$id source &amp;lt;- sapply(tax_split, second_last) ## source node source_id &amp;lt;- mapping[source,] value &amp;lt;- taxtab$V2 ## width of flow links &amp;lt;- data.</description>
    </item>
    
    <item>
      <title>超大宏基因组数据集CuratedMetagenomicData</title>
      <link>/post/2017-10-30-r-curatedmetagenomicdata/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-10-30-r-curatedmetagenomicdata/</guid>
      <description>简介 CuratedMetagenomicData(https://waldronlab.github.io/curatedMetagenomicData/)的目标是用标准化的流程（MetaPhlan2、HUMAnN2）分析已发表的宏基因组数据并建立一个统一的数据集合。目前已经收录6000余个样本并在持续扩建当中。样本涵盖糖尿病、肥胖症、IBD等多种疾病，涉及皮肤、口腔、粪便等多处样本。
 完整帮助信息 https://bioconductor.org/packages/devel/data/experiment/vignettes/curatedMetagenomicData/inst/doc/curatedMetagenomicData.html
 安装 通过Bioconductor安装最新版本
## try http:// if https:// URLs are not supported source(&amp;quot;https://bioconductor.org/biocLite.R&amp;quot;) useDevel() biocLite(&amp;quot;curatedMetagenomicData&amp;quot;)  基本使用 调用
suppressPackageStartupMessages(library(curatedMetagenomicData)) 查看metadata
combined_metadata ## # A tibble: 6,058 x 80 ## dataset_name sampleID subjectID body_site antibiotics_current_use ## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; ## 1 AsnicarF_2017 MV_FEI1_t1Q14 MV_FEI1 stool &amp;lt;NA&amp;gt; ## 2 AsnicarF_2017 MV_FEI2_t1Q14 MV_FEI2 stool &amp;lt;NA&amp;gt; ## 3 AsnicarF_2017 MV_FEI3_t1Q14 MV_FEI3 stool &amp;lt;NA&amp;gt; ## 4 AsnicarF_2017 MV_FEI4_t1Q14 MV_FEI4 stool &amp;lt;NA&amp;gt; ## 5 AsnicarF_2017 MV_FEI4_t2Q15 MV_FEI4 stool &amp;lt;NA&amp;gt; ## 6 AsnicarF_2017 MV_FEI5_t1Q14 MV_FEI5 stool &amp;lt;NA&amp;gt; ## 7 AsnicarF_2017 MV_FEI5_t2Q14 MV_FEI5 stool &amp;lt;NA&amp;gt; ## 8 AsnicarF_2017 MV_FEI5_t3Q15 MV_FEI5 stool &amp;lt;NA&amp;gt; ## 9 AsnicarF_2017 MV_FEM1_t1Q14 MV_FEM1 stool &amp;lt;NA&amp;gt; ## 10 AsnicarF_2017 MV_FEM2_t1Q14 MV_FEM2 stool &amp;lt;NA&amp;gt; ## # .</description>
    </item>
    
    <item>
      <title>桑基图（Sankey diagram）</title>
      <link>/post/2017-10-29-r-sankeyplot/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-10-29-r-sankeyplot/</guid>
      <description>简介 桑基图（Sankey diagram）是用于表示能量或信息流动的一种可视化方式，应用于微生物组数据，可以清晰展示各个taxonomy level之间物种相对丰度的流动。从Domain到Species，相邻两级之间分支的总宽度保持不变（能量守恒），如下图：  数据准备 此处我们使用Metaphlan2 tutorial中的数据，来源于牙龈菌斑的宏基因组测序：
download.file(&amp;#39;https://github.com/biobakery/biobakery/raw/master/demos/biobakery_demos/data/metaphlan2/output/SRS014476-Supragingival_plaque_profile.txt&amp;#39;, destfile = &amp;#39;SRS014476-Supragingival_plaque_profile.txt&amp;#39;) taxtab &amp;lt;- read.table(&amp;#39;SRS014476-Supragingival_plaque_profile.txt&amp;#39;, sep=&amp;#39;\t&amp;#39;, stringsAsFactors=FALSE)  加载networkdD3包 该包使用D3.js实现数据的交互式可视化，具体一些例子参见这里：
library(networkD3)  数据预处理 函数sankeyNetwork主要需要两个data frame: Links和Nodes。Links主要有连接的起点（source）和终点（target），似乎此处的起点和终点只能是从0开始的数字。Nodes如果不指定ID，默认行是按照0开始的数字排列。
second_last &amp;lt;- function(x) ifelse(length(x)&amp;gt;1, x[length(x)-1], NA) taxtab &amp;lt;- taxtab[-grep(&amp;#39;unclassified&amp;#39;, taxtab$V1), ] ## remove unlassified taxa tax_split &amp;lt;- strsplit(taxtab$V1, &amp;#39;\\|&amp;#39;) ## split into different taxonomy levels target &amp;lt;- sapply(tax_split, tail, n=1) ## target node mapping &amp;lt;- data.frame(id=0:(length(target)-1), row.names=target) target_id &amp;lt;- mapping$id source &amp;lt;- sapply(tax_split, second_last) ## source node source_id &amp;lt;- mapping[source,] value &amp;lt;- taxtab$V2 ## width of flow links &amp;lt;- data.</description>
    </item>
    
  </channel>
</rss>