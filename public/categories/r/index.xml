<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Chenhao&#39;s Personal Page</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Chenhao&#39;s Personal Page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© This site was created with R BlogDown and HuGo by Chenhao Li.</copyright>
    <lastBuildDate>Sun, 25 Nov 2018 00:00:00 +0000</lastBuildDate><atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Emacs远程连接R</title>
      <link>/post/2018-11-25-emacs-remote-r/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-25-emacs-remote-r/</guid>
      <description>本地的R脚本，远程执行</description>
    </item>
    
    <item>
      <title>一（三）文你读不懂PCA和PCoA</title>
      <link>/post/2018-04-39-r-pca_pcoa/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-04-39-r-pca_pcoa/</guid>
      <description>今天看到金唯智公众号的推文《三文读懂PCA和PCoA》（《&lt;a href=&#34;http://blog.sina.com.cn/s/blog_a0d2a3c00102xl9e.html&#34;&gt;一&lt;/a&gt;》,《&lt;a href=&#34;http://blog.sina.com.cn/s/blog_a0d2a3c00102xl9f.html&#34;&gt;二&lt;/a&gt;》,《&lt;a href=&#34;http://blog.sina.com.cn/s/blog_a0d2a3c00102xl9h.html&#34;&gt;三&lt;/a&gt;》)。作者以平民化的语言，剔除数学术语，介绍了二者的区别，是很好的尝试，但是文中提出的很多关键性总结，都存在着明显的漏洞。</description>
    </item>
    
    <item>
      <title>成分之咒与ReBoot算法</title>
      <link>/post/2018-01-12-r-compositional/</link>
      <pubDate>Fri, 12 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-12-r-compositional/</guid>
      <description>&lt;h1 id=&#34;写在前面&#34;&gt;写在前面&lt;/h1&gt;
&lt;p&gt;本文的大部分内容都来自我们之前的一篇综述文章&lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1046202315300943?via%3Dihub&#34;&gt;Li et al, 2016&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id=&#34;微生物组测序与成分数据&#34;&gt;微生物组测序与成分数据&lt;/h1&gt;
&lt;p&gt;微生物组测序数据的获得其实有很多抽样过程（Sampling process）存在，比如说，粪便微生物组其实是对肠道微生物的一次抽样，测序的过程也是对所有DNA分子的一次抽样。最后，我们得到的OTU表中的OTU read count与测序深度相关，很显然测序深度是一个技术上的干扰因子（confounder），所以我们要对OTU表进行标准化（Normalization）。最简单的标准化方法，就是用read count除以样本内所有OTU的read count之和，获得每个OTU的相对丰度（relative abundance）。这种只有相对丰度的数据（相加总数为常数1或100）被称为成分数据（Compositional data）。 你可能注意到，作为成分数据一种的微生物组的数据中缺乏一个重要的信息&amp;ndash;微生物总量（total abundance）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ggplot扩展学习笔记--逐行解析Y叔的&#34;geom_ord_ellipse.R&#34;</title>
      <link>/post/2018-01-09-r-ordellipsecode/</link>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-09-r-ordellipsecode/</guid>
      <description>看到Y叔为&lt;a href=&#34;https://github.com/fawda123/ggord&#34;&gt;ggord&lt;/a&gt;做的添加置信椭圆的&lt;a href=&#34;https://github.com/GuangchuangYu/yyplot/blob/master/R/geom_ord_ellipse.R&#34;&gt;geom_ord_ellipse.R&lt;/a&gt;（用法见&lt;a href=&#34;http://lchblogs.netlify.com/post/2017-12-29-r-addconfellipse/&#34;&gt;上一篇文章&lt;/a&gt;），决定学习一点ggplot图形的语言，对于初学者最好的方法就是照葫芦画瓢，而Y叔的代码自然是最好的模板。我对Y叔的代码进行了逐行的分析，希望以后有需要可以套用。</description>
    </item>
    
    <item>
      <title>Generalized Lotka-Volterra model</title>
      <link>/post/2017-11-15-r-glv/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-11-15-r-glv/</guid>
      <description>Relative scaling for GLV models</description>
    </item>
    
    <item>
      <title>从curatedMetagenoimcData提取健康样本的微生物组</title>
      <link>/post/2017-11-07-r-curatedmetagenomicdata_retrievedata/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-11-07-r-curatedmetagenomicdata_retrievedata/</guid>
      <description>&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;有人问我，这个curatedMetagenomicData有什么作用？对于我们这些research parasite(出处请见&lt;a href=&#34;http://www.nejm.org/doi/full/10.1056/NEJMe1516564#t=article&#34;&gt;NEJM社论&lt;/a&gt;)来说，这样庞大的数据集当然是用来挖信息或者是测试算法了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;作为validation cohort来验证已发现的结论。如我们的&lt;a href=&#34;https://www.nature.com/articles/nmicrobiol2016106&#34;&gt;这篇文章&lt;/a&gt;都使用了2014年Oh et al发表于Nature的数据来佐证我们发现的Staphylococcus特异性突变。&lt;/li&gt;
&lt;li&gt;用来测试新方法，发现新的生物问题。如&lt;a href=&#34;http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1005614&#34;&gt;这篇文章&lt;/a&gt;中我们也用了Oh et al的数据来观测Malessezia在人体皮肤的分布。&lt;/li&gt;
&lt;li&gt;因为数据中有大量健康人的微生物组（不同研究中的control），我们也可以用它们补充我们的对照组（当然在机器学习中要注意数据不平衡问题）。
当然最基础的操作，就是要从数据库中提取数据。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>桑基图（Sankey diagram）II</title>
      <link>/post/2017-11-02-r-sankeyplot2/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-11-02-r-sankeyplot2/</guid>
      <description>再次尝试桑基图</description>
    </item>
    
    <item>
      <title>超大宏基因组数据集CuratedMetagenomicData</title>
      <link>/post/2017-10-30-r-curatedmetagenomicdata/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-10-30-r-curatedmetagenomicdata/</guid>
      <description>&lt;h1 id=&#34;简介&#34;&gt;简介&lt;/h1&gt;
&lt;p&gt;CuratedMetagenomicData(&lt;a href=&#34;https://waldronlab.github.io/curatedMetagenomicData/&#34;&gt;https://waldronlab.github.io/curatedMetagenomicData/&lt;/a&gt;)的目标是用标准化的流程（MetaPhlan2、HUMAnN2）分析已发表的宏基因组数据并建立一个统一的数据集合。目前已经收录&lt;a href=&#34;https://waldronlab.github.io/curatedMetagenomicData/datasets-included/&#34;&gt;6000余个样本&lt;/a&gt;并在持续&lt;a href=&#34;https://waldronlab.github.io/curatedMetagenomicData/datasets-ongoing/&#34;&gt;扩建&lt;/a&gt;当中。样本涵盖糖尿病、肥胖症、IBD等多种疾病，涉及皮肤、口腔、粪便等多处样本。</description>
    </item>
    
    <item>
      <title>桑基图（Sankey diagram）</title>
      <link>/post/2017-10-29-r-sankeyplot/</link>
      <pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-10-29-r-sankeyplot/</guid>
      <description>桑基图（Sankey diagram）是用于表示能量或信息流动的一种可视化方式，应用于微生物组数据，可以清晰展示各个taxonomy level之间物种相对丰度的流动。从Domain到Species，相邻两级之间分支的总宽度保持不变（能量守恒），如下图</description>
    </item>
    
  </channel>
</rss>
